import os
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import re

# === ä¸‰ä¸ªæ•°æ®é›†é…ç½®ï¼ˆè·¯å¾„ + æ–‡ä»¶åï¼‰===
datasets = [
    {
        "name": "imdb",
        "result_file": "imdb_sentiment_results.csv"
    },
    {
        "name": "imdb_sklearn",
        "result_file": "imdb_sklearn_sentiment_results.csv"
    },
    {
        "name": "sst2",
        "result_file": "sst2_sentiment_results.csv"
    }
]

# === æ¨¡å‹åå­ç›®å½• ===
models = ["åŸå§‹åŸºåº§æ¨¡å‹", "Fæ€§æ ¼æ¨¡å‹", "Tæ€§æ ¼æ¨¡å‹"]

def map_sentiment_label(text):
    if not isinstance(text, str):
        return None
    # å°å†™å¤„ç† + å»æ ‡ç‚¹ï¼ˆä¿ç•™ only å­—æ¯ï¼‰
    text = re.sub(r'[^a-z]', '', text.lower())
    if "positive" in text:
        return 1
    if "negative" in text:
        return 0
    return None

# === ä¸»è¯„ä¼°æµç¨‹ ===
for dataset in datasets:
    dataset_dir = os.path.join("results", "sentiment", dataset["name"])
    result_file = dataset["result_file"]
    output_path = os.path.join(dataset_dir, f"{dataset['name']}_metrics.txt")

    with open(output_path, "w", encoding="utf-8") as f_out:
        for model in models:
            model_path = os.path.join(dataset_dir, model, result_file)
            if not os.path.exists(model_path):
                print(f"âŒ ç¼ºå¤±ç»“æœæ–‡ä»¶ï¼š{model_path}")
                continue

            df = pd.read_csv(model_path)
            if "label" not in df.columns or "prediction" not in df.columns:
                print(f"âš ï¸ æ— æ•ˆæ ¼å¼ï¼š{model_path}")
                continue

            gold_labels = df["label"].tolist()
            predictions_raw = df["prediction"].tolist()
            predictions = [map_sentiment_label(p) for p in predictions_raw]

            valid_pairs = [(y, p) for y, p in zip(gold_labels, predictions) if p is not None]

            if not valid_pairs:
                f_out.write(f"\nğŸ“Œ Model: {model}\n")
                f_out.write("accuracy: nan\nprecision: 0.0\nrecall: 0.0\nf1: 0.0\ncount: 0\n")
                f_out.write("-" * 40 + "\n")
                continue

            y_true, y_pred = zip(*valid_pairs)
            metrics = {
                "accuracy": round(accuracy_score(y_true, y_pred), 4),
                "precision": round(precision_score(y_true, y_pred), 4),
                "recall": round(recall_score(y_true, y_pred), 4),
                "f1": round(f1_score(y_true, y_pred), 4),
                "count": len(y_true)
            }

            f_out.write(f"\nğŸ“Œ Model: {model}\n")
            for k, v in metrics.items():
                f_out.write(f"{k}: {v}\n")
            f_out.write("-" * 40 + "\n")

    print(f"âœ… å·²è¯„ä¼°ï¼š{dataset['name']}ï¼Œç»“æœå†™å…¥ â†’ {output_path}")
