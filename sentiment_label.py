import os
import re
import pandas as pd
from collections import Counter, defaultdict

# ========= æ•°æ®é›†é…ç½® =========
datasets = [
    {
        "name":       "imdb_sentiment",
        "file":       "imdb_sentiment_results.csv",
        "label_map":  {"0": "negative", "1": "positive"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/imdb_sentiment",
    },
    {
        "name":       "mental_sentiment",
        "file":       "mental_sentiment_results.csv",
        "label_map":  None,
        "allowed_labels": ["normal", "depression"],
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/medical",
    },
    {
        "name":       "financial_sentiment",
        "file":       "news_sentiment_results.csv",
        "label_map":  {"0": "bearish", "1": "bullish", "2": "neutral"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/news",
    },
    {
        "name":       "fiqasa_sentiment",
        "file":       "fiqasa_results.csv",
        "label_map":  None,
        "allowed_labels": ["negative", "positive", "neutral"],
        "label_col":  "answer",
        "pred_col":   "prediction",
        "base_path":  "results/finbench",
    },
    {
        "name":       "imdb_sklearn",
        "file":       "imdb_sklearn_sentiment_results.csv",
        "label_map":  {"0": "negative", "1": "positive"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/sentiment/imdb_sklearn",
    },
    {
        "name":       "sst2",
        "file":       "sst2_sentiment_results.csv",
        "label_map":  {"0": "negative", "1": "positive"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/sentiment/sst2",
    },
]

# ========= æ¨¡å‹æ–‡ä»¶å¤¹å =========
models = {
    "base": "åŸå§‹åŸºåº§æ¨¡å‹",
    "f":    "Fæ€§æ ¼æ¨¡å‹",
    "t":    "Tæ€§æ ¼æ¨¡å‹",
}

# ========= æ–‡æœ¬æ¸…æ´—å‡½æ•° =========
def clean(text: str) -> str:
    if not isinstance(text, str):
        return ""
    return re.sub(r"[^a-z]", "", text.strip().lower())

# ========= ç»Ÿè®¡å®¹å™¨ =========
dist_all = defaultdict(lambda: defaultdict(lambda: {"true": 0, "base": 0, "f": 0, "t": 0}))

for ds in datasets:
    print(f"ğŸ” å¤„ç†æ•°æ®é›†ï¼š{ds['name']}")
    allowed = set(map(clean, ds["allowed_labels"])) if ds["allowed_labels"] else set()
    true_done = False  # åªç»Ÿè®¡ä¸€æ¬¡çœŸå®æ ‡ç­¾

    for mkey, mfolder in models.items():
        path = os.path.join(ds["base_path"], mfolder, ds["file"])
        if not os.path.exists(path):
            print(f"  âš ï¸ ç¼ºå°‘æ–‡ä»¶ï¼š{path}")
            continue

        df = pd.read_csv(path)
        original_df = df.copy()

        # --- æ˜ å°„æ ‡ç­¾ ---
        if ds["label_map"] is not None:
            df[ds["label_col"]] = df[ds["label_col"]].astype(str).map(ds["label_map"])

        # --- æ¸…æ´— ---
        df[ds["label_col"]] = df[ds["label_col"]].astype(str).apply(clean)
        df["cleaned_pred"]  = df[ds["pred_col"]].astype(str).apply(clean)

        # è‹¥æœªæ˜¾å¼ç»™ allowedï¼Œåˆ™ç”¨ label_map çš„å€¼ï¼›ä»ä¸ºç©ºæ—¶å†é€€åŒ–ä¸ºçœŸå®æ ‡ç­¾é›†åˆ
        if not allowed:
            if ds["label_map"] is not None:
                allowed = set(map(clean, ds["label_map"].values()))
            else:
                allowed = set(df[ds["label_col"]].unique())

        # --- ç»Ÿè®¡çœŸå®æ ‡ç­¾ ---
        if not true_done:
            for lbl, cnt in Counter(df[ds["label_col"]]).items():
                if lbl in allowed:
                    dist_all[ds["name"]][lbl]["true"] = cnt
            true_done = True

        # --- ç»Ÿè®¡é¢„æµ‹æ ‡ç­¾ï¼ˆå­ä¸²åŒ¹é…ï¼‰---
        for lbl in allowed:
            match_count = df["cleaned_pred"].apply(lambda x: lbl in x).sum()
            dist_all[ds["name"]][lbl][mkey] = match_count

        # === ä¿å­˜éæ³• prediction è¡Œï¼ˆä¸åŒ…å«ä»»ä½•å…³é”®è¯ï¼‰===
        is_valid = df["cleaned_pred"].apply(lambda x: any(lbl in x for lbl in allowed))
        original_df["cleaned_prediction"] = df["cleaned_pred"]
        invalid_df = original_df[~is_valid]
        if not invalid_df.empty:
            invalid_path = os.path.join(ds["base_path"], mfolder, ds["file"].replace(".csv", ".invalid.csv"))
            invalid_df.to_csv(invalid_path, index=False)
            print(f"  ğŸš« éæ³• prediction æ¡ç›®å·²ä¿å­˜è‡³ï¼š{invalid_path}")

# ========= è¾“å‡º TXT =========
outfile = "label_distribution_summary.txt"
with open(outfile, "w", encoding="utf-8") as f:
    for dname, label_dict in dist_all.items():
        f.write(f"======== {dname} ========\n")
        df_out = (
            pd.DataFrame(label_dict).T
              .fillna(0)
              .astype(int)
              .loc[:, ["true", "base", "f", "t"]]
              .rename(columns={
                  "true": "çœŸå®æ•°é‡",
                  "base": "åŸºåº§æ¨¡å‹",
                  "f":    "Fæ¨¡å‹",
                  "t":    "Tæ¨¡å‹",
              })
              .sort_index()
        )
        f.write(df_out.to_string())
        f.write("\n\n")
print(f"\nğŸ‰ ç»Ÿè®¡å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {outfile}")
