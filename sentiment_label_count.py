import os
import re
import pandas as pd
from collections import Counter, defaultdict

# ========= æ•°æ®é›†é…ç½® =========
datasets = [
    {
        "name":       "imdb_sentiment",
        "file":       "imdb_sentiment_results.processed.csv",
        "label_map":  {"0": "negative", "1": "positive"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/imdb_sentiment",
    },
    {
        "name":       "mental_sentiment",
        "file":       "mental_sentiment_results.processed.csv",
        "label_map":  None,
        "allowed_labels": ["normal", "depression"],
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/medical",
    },
    {
        "name":       "financial_sentiment",
        "file":       "news_sentiment_results.processed.csv",
        "label_map":  {"0": "bearish", "1": "bullish", "2": "neutral"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/news",
    },
    {
        "name":       "fiqasa_sentiment",
        "file":       "fiqasa_results.processed.csv",
        "label_map":  None,
        "allowed_labels": ["negative", "positive", "neutral"],
        "label_col":  "answer",
        "pred_col":   "prediction",
        "base_path":  "results/finbench",
    },
    {
        "name":       "imdb_sklearn",
        "file":       "imdb_sklearn_sentiment_results.csv",
        "label_map":  {"0": "negative", "1": "positive"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/sentiment/imdb_sklearn",
    },
    {
        "name":       "sst2",
        "file":       "sst2_sentiment_results.processed.csv",
        "label_map":  {"0": "negative", "1": "positive"},
        "allowed_labels": None,
        "label_col":  "label",
        "pred_col":   "prediction",
        "base_path":  "results/sentiment/sst2",
    },
]

# ========= æ¨¡å‹æ–‡ä»¶å¤¹å =========
models = {
    "base": "åŸå§‹åŸºåº§æ¨¡å‹",
    "f":    "Fæ€§æ ¼æ¨¡å‹",
    "t":    "Tæ€§æ ¼æ¨¡å‹",
}

# ========= æ–‡æœ¬æ¸…æ´—å‡½æ•° =========
def clean(text: str) -> str:
    if not isinstance(text, str):
        return ""
    return re.sub(r"[^a-z]", "", text.strip().lower())

# ========= è‡ªåŠ¨ä¿®å¤å‡½æ•° =========
def try_fix_csv(path, label_col, pred_col):
    with open(path, "r", encoding="utf-8-sig") as f:
        lines = f.readlines()
    header = lines[0].strip().split(",")
    if label_col not in header or pred_col not in header:
        print(f"  âš ï¸ è‡ªåŠ¨ä¿®å¤ CSVï¼šå°è¯•æ‰‹åŠ¨æ‹†åˆ† {path}")
        data = [line.strip().split(",") for line in lines[1:] if "," in line]
        if len(data) > 0:
            df = pd.DataFrame(data, columns=header)
            return df
        else:
            return pd.DataFrame()
    return None  # æ— éœ€ä¿®å¤

# ========= ç»Ÿè®¡å®¹å™¨ =========
dist_all = defaultdict(lambda: defaultdict(lambda: {"true": 0, "base": 0, "f": 0, "t": 0}))

for ds in datasets:
    print(f"ğŸ” å¤„ç†æ•°æ®é›†ï¼š{ds['name']}")
    allowed = set(map(clean, ds["allowed_labels"])) if ds["allowed_labels"] else set()
    true_done = False

    for mkey, mfolder in models.items():
        path = os.path.join(ds["base_path"], mfolder, ds["file"])
        if not os.path.exists(path):
            print(f"  âš ï¸ ç¼ºå°‘æ–‡ä»¶ï¼š{path}")
            continue

        try:
            df = pd.read_csv(path, encoding="utf-8-sig", sep=",")
            df.columns = df.columns.str.strip().str.replace('\ufeff', '', regex=False)

            # è‡ªåŠ¨ä¿®å¤ï¼ˆå¦‚æœåªæœ‰ä¸€åˆ—ï¼‰
            if ds["label_col"] not in df.columns or ds["pred_col"] not in df.columns:
                df_fixed = try_fix_csv(path, ds["label_col"], ds["pred_col"])
                if df_fixed is not None and not df_fixed.empty:
                    df = df_fixed
                else:
                    print(f"  âŒ æ— æ³•ä¿®å¤æˆ–ç¼ºå°‘å…³é”®åˆ—ï¼š{ds['label_col']} / {ds['pred_col']}")
                    continue

        except Exception as e:
            print(f"  âŒ è¯»å–å¤±è´¥ï¼š{path}ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{e}")
            continue

        # æ ‡ç­¾æ˜ å°„
        if ds["label_map"] is not None:
            df[ds["label_col"]] = df[ds["label_col"]].astype(str).map(ds["label_map"])

        # æ–‡æœ¬æ¸…æ´—
        df[ds["label_col"]] = df[ds["label_col"]].astype(str).apply(clean)
        df["cleaned_pred"]  = df[ds["pred_col"]].astype(str).apply(clean)

        # è‡ªåŠ¨æ¨å¯¼ allowed_labelsï¼ˆå¦‚æœæœªæ˜¾å¼ç»™å‡ºï¼‰
        if not allowed:
            if ds["label_map"] is not None:
                allowed = set(map(clean, ds["label_map"].values()))
            else:
                allowed = set(df[ds["label_col"]].unique())

        # ç»Ÿè®¡çœŸå®æ ‡ç­¾ï¼ˆä»…ä¸€æ¬¡ï¼‰
        if not true_done:
            for lbl, cnt in Counter(df[ds["label_col"]]).items():
                if lbl in allowed:
                    dist_all[ds["name"]][lbl]["true"] = cnt
            true_done = True

        # ç»Ÿè®¡ prediction æ‰€æœ‰æ ‡ç­¾ï¼ˆæ— è®ºæ˜¯å¦åœ¨ allowedï¼‰
        for lbl, cnt in Counter(df["cleaned_pred"]).items():
            dist_all[ds["name"]][lbl][mkey] = cnt

# ========= è¾“å‡º TXT =========
outfile = "label_distribution_summary.txt"
with open(outfile, "w", encoding="utf-8") as f:
    for dname, label_dict in dist_all.items():
        f.write(f"======== {dname} ========\n")
        df_out = (
            pd.DataFrame(label_dict).T
              .fillna(0)
              .astype(int)
              .loc[:, ["true", "base", "f", "t"]]
              .rename(columns={
                  "true": "çœŸå®æ•°é‡",
                  "base": "åŸºåº§æ¨¡å‹",
                  "f":    "Fæ¨¡å‹",
                  "t":    "Tæ¨¡å‹",
              })
              .sort_index()
        )
        f.write(df_out.to_string())
        f.write("\n\n")

print(f"\nğŸ‰ æ ‡ç­¾ç»Ÿè®¡å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {outfile}")
