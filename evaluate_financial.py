import os
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score

# æ ¹è·¯å¾„
base_path = "./results/finbench"
model_folders = ["Fæ€§æ ¼æ¨¡å‹", "Tæ€§æ ¼æ¨¡å‹", "åŸå§‹åŸºåº§æ¨¡å‹"]

# æ¯ä¸ªæ•°æ®é›†çš„è¯„ä»·æ–¹å¼ï¼ˆåˆ†ç±»æ ‡ç­¾å½’ä¸€ï¼‰
datasets = {
    "cfa_1000_results.csv": lambda x: str(x).strip().upper(),        # A/B/C
    "fiqasa_results.csv": lambda x: str(x).strip().lower(),          # positive/negative/neutral
    "german_400_results.csv": lambda x: str(x).strip().lower(),      # good/bad
    "bigdata_1400_results.csv": lambda x: str(x).strip().capitalize(),  # Rise/Fall
    "headlines_2000_results.csv": lambda x: str(x).strip().capitalize()  # Yes/No
}

# ç»“æœå®¹å™¨
results = []

for model in model_folders:
    model_path = os.path.join(base_path, model)

    for file_name, clean_fn in datasets.items():
        file_path = os.path.join(model_path, file_name)
        if not os.path.exists(file_path):
            continue

        df = pd.read_csv(file_path)
        df["label_clean"] = df["answer"].apply(clean_fn)
        df["prediction_clean"] = df["prediction"].apply(clean_fn)

        # å»é™¤æ— æ³•å¯¹æ¯”çš„æ ·æœ¬
        df_valid = df.dropna(subset=["label_clean", "prediction_clean"])
        y_true = df_valid["label_clean"]
        y_pred = df_valid["prediction_clean"]

        # è®¡ç®— accuracy å’Œ F1
        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, average="macro", zero_division=0)

        results.append({
            "æ¨¡å‹": model,
            "æ•°æ®é›†": file_name.replace("_results.csv", ""),
            "Accuracy": round(acc, 4),
            "F1": round(f1, 4)
        })

# è¾“å‡ºç»“æœè¡¨æ ¼
df_metrics = pd.DataFrame(results)
print(df_metrics)

# å¦å­˜ä¸º txt
save_path = os.path.join(base_path, "finbench_metrics_summary.txt")
with open(save_path, "w", encoding="utf-8") as f:
    for _, row in df_metrics.iterrows():
        f.write(
            f"ğŸ“Œ æ¨¡å‹: {row['æ¨¡å‹']}\n"
            f"ğŸ“Š æ•°æ®é›†: {row['æ•°æ®é›†']}\n"
            f"âœ… Accuracy: {row['Accuracy']}\n"
            f"âœ… F1 Score: {row['F1']}\n"
            f"{'-'*40}\n"
        )

print(f"\nâœ… å·²ä¿å­˜è‡³ï¼š{save_path}")
